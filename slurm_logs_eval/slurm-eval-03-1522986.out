Evaluating algorithm: ddpg
>>> ddpg | reward_mode=combined | obs=C01
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C01 --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:52
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C01 
   elapsed: 00:00:55
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C01 --prefer_best --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:54
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C01 --prefer_best
   elapsed: 00:00:52
>>> ddpg | reward_mode=combined | obs=C02
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C02 --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:53
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C02 
   elapsed: 00:00:53
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C02 --prefer_best --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:53
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C02 --prefer_best
   elapsed: 00:00:52
>>> ddpg | reward_mode=combined | obs=C03
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C03 --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:53
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C03 
   elapsed: 00:00:53
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C03 --prefer_best --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:53
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C03 --prefer_best
   elapsed: 00:00:54
>>> ddpg | reward_mode=combined | obs=C04
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C04 --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:53
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C04 
   elapsed: 00:00:53
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C04 --prefer_best --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:53
-> python run_evaluation.py --algorithms ddpg --reward_mode combined --obs_variant C04 --prefer_best
   elapsed: 00:00:53
>>> ddpg | reward_mode=temperature | obs=T01
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T01 --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T01 
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T01 --prefer_best --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T01 --prefer_best
   elapsed: 00:00:08
>>> ddpg | reward_mode=temperature | obs=T02
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T02 --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T02 
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T02 --prefer_best --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T02 --prefer_best
   elapsed: 00:00:08
>>> ddpg | reward_mode=temperature | obs=T03
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T03 --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T03 
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T03 --prefer_best --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T03 --prefer_best
   elapsed: 00:00:08
>>> ddpg | reward_mode=temperature | obs=T04
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T04 --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T04 
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T04 --prefer_best --outdoor_temperature_path data/LLEC_outdoor_temperature_5min_data.csv
   elapsed: 00:00:08
-> python run_evaluation.py --algorithms ddpg --reward_mode temperature --obs_variant T04 --prefer_best
   elapsed: 00:00:08

Total wall-time : 00:16:17
Sum of run times: 00:16:17
Done.

============================= JOB FEEDBACK =============================

Job ID: 1522986
Cluster: haic
User/Group: ii6824/iai
Account: iai
State: COMPLETED (exit code 0)
Partition: normal
Nodes: 1
Cores per node: 2
Nodelist: haicn1702
CPU Utilized: 00:16:00
CPU Efficiency: 48.63% of 00:32:54 core-walltime
Job Wall-clock time: 00:16:27
Starttime: Mon Jun 16 11:53:58 2025
Endtime: Mon Jun 16 12:10:25 2025
Memory Utilized: 728.72 MB
Memory Efficiency: 11.04% of 6.45 GB
Energy Consumed: 551452 Joule / 153.181111111111 Watthours
Average node power draw: 558.715298885512 Watt
